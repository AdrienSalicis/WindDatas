{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5ad8b5b",
   "metadata": {},
   "source": [
    "\n",
    "# WindDatas – Analyse technique des données de vent\n",
    "\n",
    "Ce notebook constitue la **base technique robuste** pour l'analyse complète des données de vent dans le cadre du projet **WindDatas**.\n",
    "\n",
    "Il a été conçu pour :\n",
    "- être **modulaire et générique**, adapté à tous les sites présents dans `../data/`\n",
    "- produire une **analyse rigoureuse, reproductible et documentée**\n",
    "- servir de fondation pour des enrichissements futurs (page de garde, exports Word, ajout de modèles, etc.)\n",
    "\n",
    "---\n",
    "\n",
    "# Bloc 1 – Imports et sélection dynamique du site\n",
    "\n",
    "Ce bloc initialise l'environnement Python pour l'analyse statistique.  \n",
    "Il détecte automatiquement les sites disponibles dans le dossier `../data/` et propose une sélection manuelle.  \n",
    "La variable `site_prefix` sert ensuite à charger les fichiers liés au site choisi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cfd0c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 📦 Imports globaux – tous en tête pour éviter les erreurs\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from math import radians\n",
    "from scipy.stats import weibull_min, gumbel_r\n",
    "import warnings\n",
    "\n",
    "# 📉 Configuration visuelle\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 4)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# 🔇 Suppression des warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aaf715e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sites disponibles :\n",
      "1. TEST_PARIS_Montsouris\n",
      "2. WFR001_PIOLENC\n",
      "3. WFR006_CARBONNE\n",
      "4. WFR049_SALLES_SUR_GARONNE\n",
      "5. WFR066_GROILLONS\n",
      "6. WFR070_MADONE\n",
      "7. WFR090_MONPEZAT\n",
      "8. WIL010_Nofar Pilot\n",
      "9. WIL017_ASHDOT\n",
      "10. WIL045_KFAR HAMACCABI (KHM)\n",
      "11. WIN160_RUMSL\n",
      "12. WIT001_PONTECORVO\n",
      "13. WJP104_YAMAKURA\n",
      "14. WLU001_DIFFERDANGE\n",
      "15. WNL001_AZALEALAAN\n",
      "16. WNL005_WATTCO (Pilot)\n",
      "17. WNL006_ALPEN WATTCO = Maxima Bridge\n",
      "18. WNL009_ENGIE POND HQ = Engie Zaandam\n",
      "19. WNL024_BURGUM CENTRAL = Engie Burgum\n",
      "20. WNL026_OOSTERHOF HOLFMAN\n",
      "21. WNL031_VELDHUNTEN\n",
      "22. WNL049_K3\n",
      "23. WNL059_ZALTBOMMEL\n",
      "24. WPT008_ALTO_RABAGAO\n",
      "25. WPT016_SAO LUIS = Cegonha\n",
      "26. WPT026_CUBA ESTE\n",
      "27. WSE001_BOR\n",
      "28. WTW059_CHANGBIN\n",
      "29. WUK003_QE2\n",
      "30. WUK013_SHEEPLANDS FARM\n",
      "31. WUK025_GODLEY RESERVOIR\n",
      "32. WUK027_KEENS FARM\n",
      "33. WUK028_WOODLANE\n",
      "34. WUK029_PARK FARM\n",
      "35. WUK045_POLYBELL\n",
      "36. WUK063_REEDERS RESERVOIR\n",
      "Site sélectionné : WTW059_CHANGBIN\n",
      "era5_CHANGBIN chargé (438336 lignes)\n",
      "era5_daily_CHANGBIN chargé (18264 lignes)\n",
      "meteostat1_CHANGBIN chargé (4395 lignes)\n",
      "meteostat2_CHANGBIN chargé (8715 lignes)\n",
      "nasa_power_CHANGBIN chargé (18264 lignes)\n",
      "noaa_station1_CHANGBIN chargé (6884 lignes)\n",
      "noaa_station2_CHANGBIN chargé (1191 lignes)\n",
      "openmeteo_CHANGBIN chargé (18264 lignes)\n",
      "power_CHANGBIN chargé (18264 lignes)\n",
      "stations_CHANGBIN.csv non chargé : Aucune colonne temporelle reconnue ('time', 'DATE', 'date')\n",
      "statistics_comparison_CHANGBIN.csv non chargé : Aucune colonne temporelle reconnue ('time', 'DATE', 'date')\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Répertoire racine des données\n",
    "data_root = Path(\"../data\")\n",
    "\n",
    "# Liste des sites disponibles (dossiers)\n",
    "site_folders = [d.name for d in data_root.iterdir() if d.is_dir()]\n",
    "site_folders.sort()\n",
    "\n",
    "print(\"Sites disponibles :\")\n",
    "for idx, folder in enumerate(site_folders, 1):\n",
    "    print(f\"{idx}. {folder}\")\n",
    "\n",
    "# Sélection du site par numéro\n",
    "site_index = int(input(\"\\nEntrez le numéro du site à analyser : \")) - 1\n",
    "selected_site = site_folders[site_index]\n",
    "print(f\"Site sélectionné : {selected_site}\")\n",
    "\n",
    "# Dossier du site sélectionné\n",
    "site_path = data_root / selected_site\n",
    "\n",
    "# Chargement de tous les fichiers CSV utiles\n",
    "dfs = {}\n",
    "\n",
    "# Liste des fichiers à ignorer explicitement (fichiers parasites)\n",
    "ignored_keywords = [\"lat\", \"lon\", \"backup\", \"temp\", \"test\"]\n",
    "\n",
    "for csv_file in site_path.glob(\"*.csv\"):\n",
    "    filename = csv_file.name\n",
    "\n",
    "    # Ignore si doublon ou fichier non exploitable (ex : avec lat/lon dans le nom)\n",
    "    if any(kw in filename.lower() for kw in ignored_keywords):\n",
    "        print(f\"Ignoré (fichier parasite) : {filename}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Auto-détection colonne de date\n",
    "        sample = pd.read_csv(csv_file, nrows=5)\n",
    "        date_col = next((col for col in [\"time\", \"DATE\", \"date\"] if col in sample.columns), None)\n",
    "\n",
    "        if date_col is None:\n",
    "            raise ValueError(\"Aucune colonne temporelle reconnue ('time', 'DATE', 'date')\")\n",
    "\n",
    "        df = pd.read_csv(csv_file, parse_dates=[date_col])\n",
    "        df = df.rename(columns={date_col: \"time\"})  # Standardisation\n",
    "        key = filename.replace(\".csv\", \"\")\n",
    "        dfs[key] = df\n",
    "        print(f\"{key} chargé ({len(df)} lignes)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{filename} non chargé : {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89d09afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✅] era5_CHANGBIN chargé (438336 lignes)\n",
      "[✅] era5_daily_CHANGBIN chargé (18264 lignes)\n",
      "[✅] meteostat1_CHANGBIN chargé (4395 lignes)\n",
      "[✅] meteostat2_CHANGBIN chargé (8715 lignes)\n",
      "[✅] nasa_power_CHANGBIN chargé (18264 lignes)\n",
      "[✅] noaa_station1_CHANGBIN chargé (6884 lignes)\n",
      "[✅] noaa_station2_CHANGBIN chargé (1191 lignes)\n",
      "[✅] openmeteo_CHANGBIN chargé (18264 lignes)\n",
      "[✅] power_CHANGBIN chargé (18264 lignes)\n",
      "[✅] stations_CHANGBIN chargé (4 lignes)\n",
      "[✅] statistics_comparison_CHANGBIN chargé (15 lignes)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 📥 Chargement automatisé des fichiers CSV\n",
    "# ============================================================\n",
    "\n",
    "dataframes = {}\n",
    "for file in os.listdir(site_path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        key = file.replace(\".csv\", \"\")\n",
    "        try:\n",
    "            df = pd.read_csv(os.path.join(site_path, file))\n",
    "            if \"time\" in df.columns:\n",
    "                df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "            elif \"date\" in df.columns:\n",
    "                df = df.rename(columns={\"date\": \"time\"})\n",
    "                df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "            if \"time\" in df.columns:\n",
    "                df = df.sort_values(\"time\")\n",
    "            dataframes[key] = df\n",
    "            print(f\"[✅] {key} chargé ({len(df)} lignes)\")\n",
    "        except Exception as e:\n",
    "            print(f\"[❌] Erreur lecture {file} : {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff348d69",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'site_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# 📍 Résumé du site et période couverte\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[32m      5\u001b[39m site_info = {\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mNom du site\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43msite_name\u001b[49m,\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mFichiers disponibles\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mlist\u001b[39m(dataframes.keys())\n\u001b[32m      8\u001b[39m }\n\u001b[32m     10\u001b[39m all_dates = []\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m dataframes.values():\n",
      "\u001b[31mNameError\u001b[39m: name 'site_name' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Résumé du site et période couverte\n",
    "# ============================================================\n",
    "\n",
    "site_info = {\n",
    "    \"Nom du site\": selected_site,\n",
    "    \"Fichiers disponibles\": list(dataframes.keys())\n",
    "}\n",
    "\n",
    "all_dates = []\n",
    "for df in dataframes.values():\n",
    "    if \"time\" in df.columns:\n",
    "        all_dates.extend(df[\"time\"].dropna().tolist())\n",
    "\n",
    "if all_dates:\n",
    "    start = min(all_dates).date()\n",
    "    end = max(all_dates).date()\n",
    "    site_info[\"Période d’étude\"] = f\"{start} → {end}\"\n",
    "else:\n",
    "    site_info[\"Période d’étude\"] = \"Inconnue\"\n",
    "\n",
    "print(\"Informations sur le site :\\n\")\n",
    "for key, value in site_info.items():\n",
    "    print(f\"- {key} : {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c14f88",
   "metadata": {},
   "source": [
    "\n",
    "## Analyse statistique des vitesses moyennes et rafales\n",
    "\n",
    "Ce bloc calcule des statistiques de base pour chaque source de données disponible :  \n",
    "- nombre de valeurs (`count`)\n",
    "- moyenne (`mean`)\n",
    "- écart-type (`std`)\n",
    "- minimum et maximum\n",
    "- quantiles à 5%, 25%, 50%, 75%, 95%\n",
    "\n",
    "Ces indicateurs permettent d'évaluer la cohérence et la dispersion des données issues de chaque source météo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4234a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 📊 Statistiques descriptives regroupées (moyenne du vent)\n",
    "# ============================================================\n",
    "\n",
    "stats_summary = {}\n",
    "for name, df in dataframes.items():\n",
    "    if \"windspeed_mean\" in df.columns:\n",
    "        stats = df[\"windspeed_mean\"].describe(percentiles=[.05, .25, .5, .75, .95])\n",
    "        stats_summary[name] = stats\n",
    "\n",
    "df_stats = pd.DataFrame(stats_summary).T[\n",
    "    [\"count\", \"mean\", \"std\", \"min\", \"5%\", \"25%\", \"50%\", \"75%\", \"95%\", \"max\"]\n",
    "]\n",
    "\n",
    "# ✅ Mise en forme visuelle à 2 décimales uniquement à l'affichage\n",
    "display(\n",
    "    df_stats.style\n",
    "    .format(precision=2)\n",
    "    .set_caption(\"📊 Statistiques descriptives des vitesses moyennes\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7479f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 📁 Dossier des données (à adapter si besoin)\n",
    "data_root = Path(\"data\")\n",
    "stat_results = []\n",
    "\n",
    "# 🔍 Recherche des fichiers CSV dans les sous-dossiers\n",
    "csv_files = list(data_root.glob(\"**/*.csv\"))\n",
    "\n",
    "# 📊 Fonction de calcul statistique\n",
    "def compute_stats(df, source_name, site_name):\n",
    "    for col in [\"windspeed_mean\", \"windspeed_gust\", \"winddirection\"]:\n",
    "        if col in df.columns:\n",
    "            data = df[col].dropna()\n",
    "            stat_results.append({\n",
    "                \"Site\": site_name,\n",
    "                \"Source\": source_name,\n",
    "                \"Variable\": col,\n",
    "                \"Count\": len(data),\n",
    "                \"Mean\": data.mean(),\n",
    "                \"Median\": data.median(),\n",
    "                \"Std\": data.std(),\n",
    "                \"Min\": data.min(),\n",
    "                \"Max\": data.max(),\n",
    "                \"P90\": data.quantile(0.90),\n",
    "                \"P95\": data.quantile(0.95),\n",
    "                \"P99\": data.quantile(0.99),\n",
    "            })\n",
    "\n",
    "# 🔄 Parcours de tous les fichiers CSV\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        site_name = file.parts[-2]  # nom du dossier du site\n",
    "        source_name = file.stem.split(\"_\")[0]  # meteostat1, noaa_station2...\n",
    "        compute_stats(df, source_name, site_name)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Erreur lecture {file}: {e}\")\n",
    "\n",
    "# 📑 Création du DataFrame récapitulatif\n",
    "df_stats = pd.DataFrame(stat_results)\n",
    "\n",
    "# 💾 Option : export CSV si besoin\n",
    "# df_stats.to_csv(\"resume_stats_vent.csv\", index=False)\n",
    "\n",
    "# 👀 Affichage interactif\n",
    "display(df_stats.head(20))  # ou df_stats si tu veux tout voir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518b9bbc",
   "metadata": {},
   "source": [
    "\n",
    "## Histogrammes des vitesses moyennes du vent\n",
    "\n",
    "Cette visualisation montre la distribution des vitesses moyennes par source, sous forme :\n",
    "- d’histogramme (comptage ou densité)\n",
    "- avec une courbe de densité lissée (KDE)\n",
    "\n",
    "Cela permet de détecter des effets de seuil, des distributions asymétriques ou des valeurs aberrantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1870da15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Histogrammes côte à côte par source (subplots)\n",
    "# ============================================================\n",
    "\n",
    "valid_sources = [(name.split('_')[0], df[\"windspeed_mean\"].dropna()) for name, df in dataframes.items()\n",
    "                 if \"windspeed_mean\" in df.columns and len(df[\"windspeed_mean\"].dropna()) >= 10]\n",
    "\n",
    "n = len(valid_sources)\n",
    "cols = 2\n",
    "rows = (n + 1) // cols\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(12, 4 * rows), constrained_layout=True)\n",
    "axes = axes.flatten() if n > 1 else [axes]\n",
    "\n",
    "for i, (name, data) in enumerate(valid_sources):\n",
    "    ax = axes[i]\n",
    "    sns.histplot(data, bins=30, kde=True, stat='density', color='steelblue', ax=ax)\n",
    "    ax.set_title(name)\n",
    "    ax.set_xlabel(\"Vitesse moyenne (m/s)\")\n",
    "    ax.set_ylabel(\"Densité\")\n",
    "    ax.grid(True)\n",
    "\n",
    "# Supprimer les sous-graphiques inutiles si n est impair\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.suptitle(\"Distribution des vitesses moyennes par source\", fontsize=14, fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2b6874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Histogrammes groupés – rafales de vent par source\n",
    "# ============================================================\n",
    "\n",
    "valid_gust_sources = [\n",
    "    (name.split('_')[0], df[\"windspeed_gust\"].dropna())\n",
    "    for name, df in dataframes.items()\n",
    "    if \"windspeed_gust\" in df.columns and len(df[\"windspeed_gust\"].dropna()) >= 10\n",
    "]\n",
    "\n",
    "n = len(valid_gust_sources)\n",
    "if not isinstance(axes, np.ndarray):\n",
    "    axes = np.array([axes])\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(12, 4 * rows), constrained_layout=True)\n",
    "\n",
    "# Correction ici\n",
    "if not isinstance(axes, np.ndarray):\n",
    "    axes = np.array([axes])\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (name, data) in enumerate(valid_gust_sources):\n",
    "    ax = axes[i]\n",
    "    sns.histplot(data, bins=30, kde=True, stat='density', color='salmon', ax=ax)\n",
    "    ax.set_title(name, fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel(\"Rafale max (m/s)\")\n",
    "    ax.set_ylabel(\"Densité\")\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.suptitle(\"Distribution des rafales de vent par source\", fontsize=14, fontweight='bold')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4db02c9",
   "metadata": {},
   "source": [
    "\n",
    "## Comparaison visuelle – Boxplot\n",
    "\n",
    "Le boxplot (ou boîte à moustaches) affiche :\n",
    "- médiane (trait central)\n",
    "- quartiles (boîte)\n",
    "- valeurs extrêmes (points hors boîte)\n",
    "\n",
    "Il est utilisé ici pour comparer visuellement les distributions de vitesses moyennes entre sources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc69bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Boxplot avec outliers visibles + comptage des extrêmes\n",
    "# ============================================================\n",
    "\n",
    "# Fusionner les données\n",
    "df_all_box = pd.concat([\n",
    "    df.assign(source=name.split(\"_\")[0])  # Nettoyage du nom\n",
    "    for name, df in dataframes.items()\n",
    "    if \"windspeed_mean\" in df.columns\n",
    "], ignore_index=True)\n",
    "\n",
    "\n",
    "# Détection des outliers par Tukey (Q3 + 1.5 × IQR)\n",
    "outlier_counts = {}\n",
    "for source in df_all_box[\"source\"].unique():\n",
    "    data = df_all_box[df_all_box[\"source\"] == source][\"windspeed_mean\"].dropna()\n",
    "    if len(data) < 10:\n",
    "        continue\n",
    "    q1 = np.percentile(data, 25)\n",
    "    q3 = np.percentile(data, 75)\n",
    "    iqr_val = q3 - q1\n",
    "    seuil_sup = q3 + 1.5 * iqr_val\n",
    "    outlier_counts[source] = (data > seuil_sup).sum()\n",
    "\n",
    "# Afficher le tableau\n",
    "outlier_df = pd.DataFrame.from_dict(outlier_counts, orient=\"index\", columns=[\"outliers\"])\n",
    "display(outlier_df.sort_values(by=\"outliers\", ascending=False).style.set_caption(\"🔍 Nombre de valeurs extrêmes par source (> Q3 + 1.5×IQR)\"))\n",
    "\n",
    "# Afficher le boxplot avec outliers\n",
    "fig, ax = plt.subplots(figsize=(max(10, len(outlier_counts) * 1.5), 6))\n",
    "sns.boxplot(\n",
    "    data=df_all_box,\n",
    "    x=\"source\",\n",
    "    y=\"windspeed_mean\",\n",
    "    order=outlier_df.index,\n",
    "    showfliers=True,\n",
    "    flierprops=dict(marker='o', markersize=3, alpha=0.4),\n",
    "    palette=\"Set2\",\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ax.set_title(\"Boxplot des vitesses moyennes avec outliers visibles (transparence)\")\n",
    "ax.set_ylabel(\"Vitesse moyenne (m/s)\")\n",
    "ax.set_xlabel(\"Source\")\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 🔹 Histogramme du nombre de valeurs extrêmes\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "sns.barplot(\n",
    "    x=outlier_df.index,\n",
    "    y=outlier_df[\"outliers\"],\n",
    "    palette=\"rocket\",\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title(\"📊 Nombre de valeurs extrêmes (> Q3 + 1.5×IQR) par source\")\n",
    "ax.set_ylabel(\"Nombre de valeurs extrêmes\")\n",
    "ax.set_xlabel(\"Source\")\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498e3173",
   "metadata": {},
   "source": [
    "\n",
    "## Détection des valeurs extrêmes (potentiellement aberrantes)\n",
    "\n",
    "Certaines valeurs de vent très élevées peuvent correspondre à :\n",
    "- des évènements météorologiques rares\n",
    "- ou des erreurs de capteur / données mal encodées\n",
    "\n",
    "Ce bloc détecte les valeurs supérieures à un seuil configurable (`50 m/s` par défaut), et les affiche classées par ordre décroissant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d727b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 🚨 Détection des vitesses moyennes ou rafales anormales (seuil par type)\n",
    "# ============================================================\n",
    "\n",
    "seuils_min = {\n",
    "    \"windspeed_mean\": 8,\n",
    "    \"windspeed_gust\": 15\n",
    "}\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    for col in [\"windspeed_gust\", \"windspeed_mean\"]:\n",
    "        if col in df.columns:\n",
    "            data = df[col].dropna()\n",
    "            if data.empty:\n",
    "                continue\n",
    "\n",
    "            seuil = max(seuils_min[col], data.quantile(0.95))\n",
    "            extremes = df[df[col] > seuil]\n",
    "\n",
    "            print(f\"📊 {name} – {col} – max: {data.max():.2f} m/s – seuil: {seuil:.2f} m/s\")\n",
    "            if not extremes.empty:\n",
    "                print(f\"⚠️ {len(extremes)} valeurs > seuil ({seuil:.2f} m/s)\")\n",
    "                display(extremes.sort_values(by=col, ascending=False)[[\"time\", col]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d419136",
   "metadata": {},
   "source": [
    "\n",
    "## Ajustement de lois de probabilité : Weibull et Gumbel\n",
    "\n",
    "Nous utilisons deux lois statistiques classiques pour modéliser les vitesses de vent :\n",
    "- **Weibull** : forme + échelle\n",
    "- **Gumbel** : spécialisée dans l’étude des maxima (vents extrêmes)\n",
    "\n",
    "Ces courbes sont ajustées sur les données observées pour chaque source, puis comparées visuellement à l’histogramme empirique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f43ce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# Ajustement de la loi de Weibull et Gumbel\n",
    "# ============================================================\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    col = \"windspeed_gust\" if \"windspeed_gust\" in df.columns else \"windspeed_mean\"\n",
    "    if col not in df.columns:\n",
    "        continue\n",
    "\n",
    "    data = df[col].dropna()\n",
    "    if len(data) < 30:\n",
    "        continue  # pas assez de données pour ajustement fiable\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(data, bins=30, stat='density', color='lightgray', label=\"Données empiriques\")\n",
    "\n",
    "    x_vals = np.linspace(data.min(), data.max(), 200)\n",
    "\n",
    "    # Loi de Weibull (2 paramètres)\n",
    "    c, loc, scale = weibull_min.fit(data, floc=0)\n",
    "    weibull_pdf = weibull_min.pdf(x_vals, c, loc, scale)\n",
    "    plt.plot(x_vals, weibull_pdf, label=f\"Weibull (c={c:.2f}, scale={scale:.2f})\")\n",
    "\n",
    "    # Loi de Gumbel (maximum)\n",
    "    loc_g, scale_g = gumbel_r.fit(data)\n",
    "    gumbel_pdf = gumbel_r.pdf(x_vals, loc_g, scale_g)\n",
    "    plt.plot(x_vals, gumbel_pdf, label=\"Gumbel\")\n",
    "\n",
    "    plt.title(f\"Ajustement statistique – {name}\")\n",
    "    plt.xlabel(\"Vitesse (m/s)\")\n",
    "    plt.ylabel(\"Densité\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ee1d4d",
   "metadata": {},
   "source": [
    "## Comparaison croisée entre sources\n",
    "\n",
    "Pour chaque paire de sources disponibles, nous comparons les valeurs disponibles en commun :\n",
    "- Erreur absolue moyenne (MAE)\n",
    "- Corrélation linéaire (Pearson)\n",
    "- Nombre de jours communs\n",
    "\n",
    "Les résultats sont affichés de manière synthétique et lisible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45906fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 🔁 Comparaison croisée – séparée pour windspeed_mean et windspeed_gust\n",
    "# ============================================================\n",
    "\n",
    "def compare_sources_by_variable(dataframes, variable):\n",
    "    results = []\n",
    "    keys = [k for k in dataframes.keys() if variable in dataframes[k].columns and \"statistics\" not in k]\n",
    "\n",
    "    for i in range(len(keys)):\n",
    "        for j in range(i + 1, len(keys)):\n",
    "            df1 = dataframes[keys[i]]\n",
    "            df2 = dataframes[keys[j]]\n",
    "            label1 = keys[i].split('_')[0]\n",
    "            label2 = keys[j].split('_')[0]\n",
    "\n",
    "            if label1 == label2:\n",
    "                label1 += \"_1\"\n",
    "                label2 += \"_2\"\n",
    "\n",
    "            df1r = df1[[\"time\", variable]].rename(columns={variable: label1}).dropna()\n",
    "            df2r = df2[[\"time\", variable]].rename(columns={variable: label2}).dropna()\n",
    "\n",
    "            merged = pd.merge(df1r, df2r, on=\"time\").dropna()\n",
    "            if merged.empty:\n",
    "                print(f\"[⚠️] Données fusionnées nulles entre {label1} et {label2} ({variable})\")\n",
    "                continue\n",
    "\n",
    "            mae = (merged[label1] - merged[label2]).abs().mean()\n",
    "            corr = merged[label1].corr(merged[label2])\n",
    "            results.append({\n",
    "                \"source_1\": label1,\n",
    "                \"source_2\": label2,\n",
    "                \"MAE\": round(mae, 2),\n",
    "                \"corrélation\": round(corr, 3),\n",
    "                \"nb_jours\": len(merged),\n",
    "                \"variable\": variable\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Comparaisons séparées\n",
    "df_mean = compare_sources_by_variable(dataframes, \"windspeed_mean\")\n",
    "df_gust = compare_sources_by_variable(dataframes, \"windspeed_gust\")\n",
    "\n",
    "def show_comparison(df, titre):\n",
    "    if df.empty:\n",
    "        print(f\"❌ Aucune comparaison valide pour {titre}\")\n",
    "        return\n",
    "    styled = (\n",
    "        df.sort_values(by=\"MAE\", na_position=\"last\")\n",
    "        .style\n",
    "        .format({\"MAE\": \"{:.2f}\", \"corrélation\": \"{:.3f}\", \"nb_jours\": \"{:,.0f}\"}, na_rep=\"—\")\n",
    "        .background_gradient(subset=[\"MAE\"], cmap=\"Reds\")\n",
    "        .background_gradient(subset=[\"corrélation\"], cmap=\"Blues\")\n",
    "        .set_caption(f\"🔁 Comparaison croisée – {titre}\")\n",
    "        .set_properties(**{\"text-align\": \"center\"})\n",
    "        .set_table_styles([{\n",
    "            'selector': 'caption',\n",
    "            'props': [('caption-side', 'top'), ('font-weight', 'bold')]\n",
    "        }])\n",
    "    )\n",
    "    display(styled)\n",
    "\n",
    "# 📊 Affichage des résultats\n",
    "show_comparison(df_mean, \"Vitesses moyennes (windspeed_mean)\")\n",
    "show_comparison(df_gust, \"Rafales (windspeed_gust)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc08714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 📊 Résumé qualité des données – windspeed_mean & gust\n",
    "# ============================================================\n",
    "\n",
    "resume_qualite = []\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    if \"time\" not in df.columns:\n",
    "        continue\n",
    "\n",
    "    nb_jours = len(df)\n",
    "    date_min = df[\"time\"].min().date()\n",
    "    date_max = df[\"time\"].max().date()\n",
    "\n",
    "    if \"windspeed_mean\" in df.columns:\n",
    "        taux_nan_mean = f\"{df['windspeed_mean'].isna().mean():.2%}\"\n",
    "    else:\n",
    "        taux_nan_mean = \"—\"\n",
    "\n",
    "    if \"windspeed_gust\" in df.columns:\n",
    "        taux_nan_gust = f\"{df['windspeed_gust'].isna().mean():.2%}\"\n",
    "    else:\n",
    "        taux_nan_gust = \"—\"\n",
    "\n",
    "    resume_qualite.append({\n",
    "        \"Source\": name,\n",
    "        \"Nb jours\": nb_jours,\n",
    "        \"Début\": date_min,\n",
    "        \"Fin\": date_max,\n",
    "        \"NaN (windspeed_mean)\": taux_nan_mean,\n",
    "        \"NaN (windspeed_gust)\": taux_nan_gust\n",
    "    })\n",
    "\n",
    "# Création du DataFrame\n",
    "df_resume = pd.DataFrame(resume_qualite)\n",
    "\n",
    "# Résumé de la période commune ou variable\n",
    "plages = df_resume[[\"Début\", \"Fin\"]].drop_duplicates()\n",
    "if len(plages) == 1:\n",
    "    date_info = f\"📅 Période commune : {plages.iloc[0]['Début']} → {plages.iloc[0]['Fin']}\"\n",
    "    df_resume.drop(columns=[\"Début\", \"Fin\"], inplace=True)\n",
    "else:\n",
    "    date_info = \"📅 Périodes variables selon les sources\"\n",
    "\n",
    "# Affichage stylisé\n",
    "styled = (\n",
    "    df_resume\n",
    "    .style\n",
    "    .hide(axis=\"index\")\n",
    "    .set_caption(f\"📊 Résumé de la qualité des données (vent moyen et rafales)\\n{date_info}\")\n",
    "    .set_properties(**{\"text-align\": \"center\"})\n",
    "    .set_table_styles([\n",
    "        {'selector': 'caption', 'props': [('caption-side', 'top'), ('font-weight', 'bold'), ('font-size', '14px')]}\n",
    "    ])\n",
    "    .applymap(lambda val: \"color: red\" if isinstance(val, str) and \"%\" in val and float(val.strip('%')) > 10 else \"\")\n",
    ")\n",
    "\n",
    "display(styled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd7a4c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_interactive(dataframes, variable):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for name, df in dataframes.items():\n",
    "        if \"time\" not in df.columns or variable not in df.columns:\n",
    "            continue\n",
    "        trace_name = name.replace(\"_\", \" \")\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df[\"time\"],\n",
    "            y=df[variable],\n",
    "            mode=\"lines\",\n",
    "            name=trace_name,\n",
    "            line=dict(width=1),\n",
    "            hovertemplate=trace_name + \"<br>Date: %{x}<br>\" + variable + \": %{y:.2f} m/s<extra></extra>\"\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"{variable} – Données brutes par source\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"Vitesse (m/s)\",\n",
    "        template=\"plotly_white\",\n",
    "        hovermode=\"x unified\",\n",
    "        legend_title=\"Sources\",\n",
    "        height=500\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# 🌀 Exemple d'affichage\n",
    "plot_interactive(dataframes, \"windspeed_mean\")\n",
    "plot_interactive(dataframes, \"windspeed_gust\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce66eef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 💥 Analyse des jours à rafales extrêmes (> 25 m/s)\n",
    "#    - Suppression des 5 premières lignes\n",
    "#    - Affichage des rafales les plus fortes\n",
    "#    - Répartition annuelle\n",
    "# ============================================================\n",
    "\n",
    "seuil = 25  # seuil de vent extrême en m/s\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    if \"windspeed_gust\" not in df.columns or \"time\" not in df.columns:\n",
    "        continue\n",
    "\n",
    "    df = df.iloc[5:]  # 🔻 Supprimer les 5 premières lignes\n",
    "    extremes = df[df[\"windspeed_gust\"] > seuil]\n",
    "\n",
    "    print(f\"\\n💥 {name} – {len(extremes)} jours > {seuil} m/s\")\n",
    "\n",
    "    if not extremes.empty:\n",
    "        # 🔝 Afficher les rafales les plus fortes (top 5)\n",
    "        print(\"📈 Top rafales les plus fortes :\")\n",
    "        display(extremes.sort_values(by=\"windspeed_gust\", ascending=False)[[\"time\", \"windspeed_gust\"]].head())\n",
    "\n",
    "        # 📅 Résumé annuel\n",
    "        extremes[\"year\"] = extremes[\"time\"].dt.year\n",
    "        counts = extremes.groupby(\"year\").size().reset_index(name=\"nb_jours > 25 m/s\")\n",
    "\n",
    "        print(\"📆 Nombre de jours extrêmes par an :\")\n",
    "        display(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2f0554",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 📐 Ajustement de la loi de Weibull\n",
    "from scipy.stats import weibull_min\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    if \"windspeed_mean\" in df.columns:\n",
    "        data = df[\"windspeed_mean\"].dropna()\n",
    "        if not data.empty:\n",
    "            params = weibull_min.fit(data, floc=0)\n",
    "            print(f\"Weibull – {name} : shape={params[0]:.2f}, scale={params[2]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b6b0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 📎 Chargement des statistiques de comparaison inter-sources\n",
    "import glob\n",
    "\n",
    "csv_stats = glob.glob(os.path.join(data_path, \"statistics_comparison_*.csv\"))\n",
    "if csv_stats:\n",
    "    df_stats = pd.read_csv(csv_stats[0])\n",
    "    display(df_stats.style.background_gradient(axis=0, cmap=\"Blues\"))\n",
    "else:\n",
    "    print(\"Aucune comparaison statistique trouvée.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77610fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "winddatas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
